{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_api_key\n",
    "API_KEY = load_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q langchain langchain_community langchain_chroma langchain_ollama beautifulsoup4\n",
    "#!pip install langchain-openai tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_family = \"openai\"\n",
    "# model_family = \"ollama\"\n",
    "\n",
    "if model_family == \"ollama\":\n",
    "    from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "    llm = ChatOllama(model=\"llama3.2\")\n",
    "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    \n",
    "elif model_family == \"openai\":\n",
    "    from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader, TextLoader\n",
    "#from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Agent with Web based information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo .txt\n",
    "# document_loader = TextLoader(\"data.txt\", encoding=\"utf-8\")\n",
    "# documents = document_loader.load()\n",
    "\n",
    "# Ejemplo web\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=([\"https://lilianweng.github.io/posts/2023-06-23-agent/\"]),\n",
    "    bs_kwargs={\n",
    "        \"parse_only\": bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    }\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].page_content[1:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "# BORRAR BASE DE DATOS ANTES DE EJECUTAR LA SIGUIENTE LINEA\n",
    "vectordb = Chroma.from_documents(documents=split_docs, embedding=embeddings, persist_directory=\"./../../data/4_rag_agent_llm_chroma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectordb._collection.get(include=['embeddings'])[\"embeddings\"][0]\n",
    "#len(vectordb._collection.get(include=['embeddings'])[\"embeddings\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_blog = create_retriever_tool(\n",
    "    retriever=retriever, \n",
    "    name=\"blog_article_retriever\",\n",
    "    description=\"Searches and returns excerpts about LLM Agents from the blog article\",\n",
    ")\n",
    "tools = [tool_blog]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(\n",
    "    llm,\n",
    "    tools=tools,\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent_executor.invoke(\n",
    "    {\"messages\": \"¿Qué es un agente LLM? Dame la respuesta en español\"},\n",
    ")\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Añadir datos desde archivo local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent_executor.invoke(\n",
    "    {\"messages\": \"¿Cuántos días de baja por enfermedad tienen derecho los empleados de Lumon Industries anualmente?\"},\n",
    ")\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_loader = TextLoader(\"../../data/lumon_data.txt\", encoding=\"utf-8\")\n",
    "docs_txt = document_loader.load()\n",
    "\n",
    "split_docs = text_splitter.split_documents(docs_txt)\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=split_docs, embedding=embeddings, persist_directory=\"./../../data/4_rag_agent_lumon_chroma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_lumon = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "retriever_lumon\n",
    "\n",
    "tool_lumon = create_retriever_tool(\n",
    "    retriever=retriever_lumon, \n",
    "    name=\"Lumon_documentation\",\n",
    "    description=\"Searches and returns excerpts from the Lumon Industries internal documentation\",\n",
    ")\n",
    "tools = [tool_blog, tool_lumon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor_rag = create_react_agent(\n",
    "    llm,\n",
    "    tools=tools,\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent_executor_rag.invoke(\n",
    "    {\"messages\": \"¿Cuántos días de baja por enfermedad tienen derecho los empleados de Lumon Industries anualmente?\"},\n",
    ")\n",
    "#for message in response['messages']:\n",
    "#    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"¿Cuántos días de baja por enfermedad tienen derecho los empleados de Lumon Industries anualmente?\",\n",
    "    \"¿Cuál es la contraseña de la red de invitados de Lumon Industries?\",\n",
    "    \"¿Cuánto dura la garantía de los productos de Lumon Industries?\",\n",
    "    \"¿A quién debo contactar si tengo problemas con los productos de Lumon Industries?\",\n",
    "    \"¿Cuál es el horario de atención al cliente de Lumon Industries? Devuelve solamente el dato, nada más.\",\n",
    "]\n",
    "\n",
    "# Compare responses from both methods\n",
    "results = []\n",
    "for query in queries:\n",
    "    rag_response = agent_executor_rag.invoke({\"messages\": query})['messages'][-1].content\n",
    "    gpt4o_response = agent_executor.invoke({\"messages\": query})['messages'][-1].content\n",
    "    results.append({\"Query\": query, \"RAG Response\": rag_response, \"GPT-4o Response\": gpt4o_response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Convert results to a dataframe and display\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Function to wrap text in all string columns\n",
    "def wrap_dataframe_text(df, width=40):\n",
    "    wrapped_df = df.copy()\n",
    "    for col in wrapped_df.select_dtypes(include=['object']).columns:\n",
    "        wrapped_df[col] = wrapped_df[col].apply(lambda x: \"\\n\".join(textwrap.wrap(x, width)) if isinstance(x, str) else x)\n",
    "    return wrapped_df\n",
    "\n",
    "# Apply text wrapping to all string columns\n",
    "df_wrapped = wrap_dataframe_text(df, width=30)\n",
    "\n",
    "# Display DataFrame as a formatted table\n",
    "print(tabulate(df_wrapped, headers='keys', tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent_executor_rag.invoke(\n",
    "    {\"messages\": \"¿Qué es un agente LLM? Dame la respuesta en español\"},\n",
    ")\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proceso similar para excel, CSV, PDF, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
