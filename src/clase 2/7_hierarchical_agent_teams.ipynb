{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_api_key, streaming_print\n",
    "API_KEY = load_api_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Agent Teams\n",
    "\n",
    "[Source](https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/multi_agent/hierarchical_agent_teams.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools Definition\n",
    "\n",
    "### Research team tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research team tools\n",
    "from typing import Annotated, List\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "tavily_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "\n",
    "@tool\n",
    "def scrape_webpages(urls: List[str]) -> str:\n",
    "    \"\"\"Use requests and bs4 to scrape the provided web pages for detailed information.\"\"\"\n",
    "    loader = WebBaseLoader(urls)\n",
    "    docs = loader.load()\n",
    "    return \"\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document name=\"{doc.metadata.get(\"title\", \"\")}\">\\n{doc.page_content}\\n</Document>'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing team tools\n",
    "\n",
    "- Resumir texto en bullet points\n",
    "- Leer, escribir y editar archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing team tools\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Dict, Optional\n",
    "\n",
    "# from langchain_experimental.utilities import PythonREPL\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "_TEMP_DIRECTORY = TemporaryDirectory()\n",
    "_TEMP_DIRECTORY = \"../../output/\"\n",
    "# WORKING_DIRECTORY = Path(_TEMP_DIRECTORY.name)\n",
    "WORKING_DIRECTORY = Path(_TEMP_DIRECTORY)\n",
    "\n",
    "\n",
    "@tool\n",
    "def read_document(\n",
    "    file_name: Annotated[str, \"File path to read the document from.\"],\n",
    "    start: Annotated[Optional[int], \"The start line. Default is 0\"] = None,\n",
    "    end: Annotated[Optional[int], \"The end line. Default is None\"] = None,\n",
    ") -> str:\n",
    "    \"\"\"Read the specified document.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    if start is None:\n",
    "        start = 0\n",
    "    return \"\\n\".join(lines[start:end])\n",
    "\n",
    "\n",
    "@tool\n",
    "def write_document(\n",
    "    content: Annotated[str, \"Text content to be written into the document.\"],\n",
    "    file_name: Annotated[str, \"File path to save the document.\"],\n",
    ") -> Annotated[str, \"Path of the saved document file.\"]:\n",
    "    \"\"\"Create and save a text document.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "        file.write(content)\n",
    "    return f\"Document saved to {file_name}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def edit_document(\n",
    "    file_name: Annotated[str, \"Path of the document to be edited.\"],\n",
    "    inserts: Annotated[\n",
    "        Dict[int, str],\n",
    "        \"Dictionary where key is the line number (1-indexed) and value is the text to be inserted at that line.\",\n",
    "    ],\n",
    ") -> Annotated[str, \"Path of the edited document file.\"]:\n",
    "    \"\"\"Edit a document by inserting text at specific line numbers.\"\"\"\n",
    "\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    sorted_inserts = sorted(inserts.items())\n",
    "\n",
    "    for line_number, text in sorted_inserts:\n",
    "        if 1 <= line_number <= len(lines) + 1:\n",
    "            lines.insert(line_number - 1, text + \"\\n\")\n",
    "        else:\n",
    "            return f\"Error: Line number {line_number} is out of range.\"\n",
    "\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "    return f\"Document edited and saved to {file_name}\"\n",
    "\n",
    "@tool\n",
    "def create_outline(\n",
    "    points: Annotated[List[str], \"List of main points or sections.\"],\n",
    "    file_name: Annotated[str, \"File path to save the outline.\"],\n",
    ") -> Annotated[str, \"Path of the saved outline file.\"]:\n",
    "    \"\"\"Create and save an outline.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "        for i, point in enumerate(points):\n",
    "            file.write(f\"{i + 1}. {point}\\n\")\n",
    "    return f\"Outline saved to {file_name}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function\n",
    "\n",
    "- `make_supervisor_node`: Crea un nodo supervisor. Lo tendremos que ejecutar 3 veces para crear los 3 nodos supervisores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Literal\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import HumanMessage, trim_messages\n",
    "\n",
    "\n",
    "class State(MessagesState):\n",
    "    next: str\n",
    "\n",
    "\n",
    "def make_supervisor_node(llm: BaseChatModel, members: list[str]) -> str:\n",
    "    options = [\"FINISH\"] + members\n",
    "    system_prompt = (\n",
    "        \"You are a supervisor tasked with managing a conversation between the\"\n",
    "        f\" following workers: {members}. Given the following user request,\"\n",
    "        \" respond with the worker to act next. Each worker will perform a\"\n",
    "        \" task and respond with their results and status. When finished,\"\n",
    "        \" respond with FINISH.\"\n",
    "    )\n",
    "\n",
    "    class Router(TypedDict):\n",
    "        \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n",
    "\n",
    "        next: Literal[*options]\n",
    "\n",
    "    def supervisor_node(state: State) -> Command[Literal[*members, \"__end__\"]]:\n",
    "        \"\"\"An LLM-based router.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "        ] + state[\"messages\"]\n",
    "        response = llm.with_structured_output(Router).invoke(messages)\n",
    "        goto = response[\"next\"]\n",
    "        if goto == \"FINISH\":\n",
    "            goto = END\n",
    "\n",
    "        return Command(goto=goto, update={\"next\": goto})\n",
    "\n",
    "    return supervisor_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# ============= Search Agent =============\n",
    "search_agent = create_react_agent(llm, tools=[tavily_tool])\n",
    "\n",
    "def search_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = search_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"search\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "# ============= Web Scraper Agent =============\n",
    "web_scraper_agent = create_react_agent(llm, tools=[scrape_webpages])\n",
    "\n",
    "def web_scraper_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = web_scraper_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"web_scraper\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "# ============= Supervisor Node =============\n",
    "research_supervisor_node = make_supervisor_node(llm, [\"search\", \"web_scraper\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_builder = StateGraph(State)\n",
    "research_builder.add_node(\"supervisor\", research_supervisor_node)\n",
    "research_builder.add_node(\"search\", search_node)\n",
    "research_builder.add_node(\"web_scraper\", web_scraper_node)\n",
    "\n",
    "research_builder.add_edge(START, \"supervisor\")\n",
    "research_graph = research_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(research_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "for s in research_graph.stream(\n",
    "    {\"messages\": [(\"user\", \"Are there any interesting articles on the front page of https://news.ycombinator.com/ about LLM Agents?\")]}, \n",
    "    {\"recursion_limit\": 100},\n",
    "):\n",
    "    print(s)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Writing team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# ============= Document Writing Agent =============\n",
    "doc_writer_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[write_document, edit_document, read_document],\n",
    "    prompt=(\n",
    "        \"You are a creative writer tasked with expanding on an outline provided by the note-taker agent. \"\n",
    "        \"Using the outline as your guide, craft a complete and engaging text that fully explores the theme. \"\n",
    "        \"Expand each point with detailed descriptions, examples, and creative language that brings the subject to life. \"\n",
    "        \"Ensure your text is coherent, well-structured, and reflects the depth of the original outline while captivating the reader.\"\n",
    "        \"Your output filename should start with 'document_' and end with '.txt'.\"\n",
    "        \"Don't ask follow-up questions.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "def doc_writing_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = doc_writer_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"doc_writer\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "# ============= Note Taking Agent =============\n",
    "note_taking_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[create_outline, read_document],\n",
    "    prompt=(\n",
    "        \"You are a detail-oriented note-taker and outline generator. \"\n",
    "        \"When given a theme or subject by the user, create a comprehensive outline that breaks down the main ideas, subtopics, and supporting details. \"\n",
    "        \"Use clear headings, bullet points, or numbered sections to organize your thoughts logically. \"\n",
    "        \"Your outline should capture the essence of the theme in a structured way that will serve as a roadmap for further elaboration.\"\n",
    "        \"You can not write the document, only the outline.\"\n",
    "        \"Your output filename should start with 'outline_' and end with '.txt'.\"\n",
    "        \"Don't ask follow-up questions.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "def note_taking_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = note_taking_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"draft_writer\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "doc_writing_supervisor_node = make_supervisor_node(\n",
    "    llm, [\"doc_writer\", \"draft_writer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph here\n",
    "paper_writing_builder = StateGraph(State)\n",
    "paper_writing_builder.add_node(\"supervisor\", doc_writing_supervisor_node)\n",
    "paper_writing_builder.add_node(\"doc_writer\", doc_writing_node)\n",
    "paper_writing_builder.add_node(\"draft_writer\", note_taking_node)\n",
    "\n",
    "paper_writing_builder.add_edge(START, \"supervisor\")\n",
    "paper_writing_graph = paper_writing_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(paper_writing_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in paper_writing_graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Escribe un poema sobre las cualidades de los gatos. Guarda el poema y en un archivo.\",\n",
    "            )\n",
    "        ]\n",
    "    },\n",
    "    {\"recursion_limit\": 100},\n",
    "):\n",
    "    print(s)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unir ambos equipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "teams_supervisor_node = make_supervisor_node(llm, [\"research_team\", \"writing_team\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_research_team(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    response = research_graph.invoke({\"messages\": state[\"messages\"][-1]})\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=response[\"messages\"][-1].content, name=\"research_team\"\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "def call_paper_writing_team(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    response = paper_writing_graph.invoke({\"messages\": state[\"messages\"][-1]})\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=response[\"messages\"][-1].content, name=\"writing_team\"\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the graph.\n",
    "super_builder = StateGraph(State)\n",
    "super_builder.add_node(\"supervisor\", teams_supervisor_node)\n",
    "super_builder.add_node(\"research_team\", call_research_team)\n",
    "super_builder.add_node(\"writing_team\", call_paper_writing_team)\n",
    "\n",
    "super_builder.add_edge(START, \"supervisor\")\n",
    "super_graph = super_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(super_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in super_graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\"user\", \"Research AI agents and write a brief report about them. We are on March 2025.\")\n",
    "        ],\n",
    "    },\n",
    "    {\"recursion_limit\": 150},\n",
    "):\n",
    "    print(s)\n",
    "    print(\"---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
